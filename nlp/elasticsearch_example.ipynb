{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "elasticsearch_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okjP8UfE8azQ"
      },
      "source": [
        "# elasticsearchを用いた日本語文章検索のサンプルコード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj9REoOvyeWd"
      },
      "source": [
        "## 環境構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJTbwYV_K68D"
      },
      "source": [
        "ES_VERSION = \"7.9.0\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gn6uLgaCNS6",
        "outputId": "2ac44647-8693-4443-8c7e-c04f0fd03f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-{ES_VERSION}-linux-x86_64.tar.gz -q\n",
        "!tar -xzf elasticsearch-{ES_VERSION}-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-{ES_VERSION}\n",
        "!pip install \"elasticsearch<8.0.0\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting elasticsearch<8.0.0\n",
            "  Downloading elasticsearch-7.17.2-py2.py3-none-any.whl (385 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 385 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch<8.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch<8.0.0) (2021.10.8)\n",
            "Installing collected packages: elasticsearch\n",
            "Successfully installed elasticsearch-7.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO5OsXgfFarN"
      },
      "source": [
        "!mkdir -p elasticsearch-{ES_VERSION}/data\n",
        "!chown -R daemon:daemon \"elasticsearch-{ES_VERSION}/data\"\n",
        "!chmod -R 755 \"elasticsearch-{ES_VERSION}/data\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unbNB0bHKGwD",
        "outputId": "210a95dc-e975-4412-89f8-da0ccfd5167d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!elasticsearch-{ES_VERSION}/bin/elasticsearch-plugin install analysis-kuromoji"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Installing analysis-kuromoji\n",
            "-> Downloading analysis-kuromoji from elastic\n",
            "[=================================================] 100%   \n",
            "-> Installed analysis-kuromoji\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfcGZNQqKfCm",
        "outputId": "861d5ee8-6818-4ac9-9bfb-2593bf5270f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!elasticsearch-{ES_VERSION}/bin/elasticsearch-plugin list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "analysis-kuromoji\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# elasticsearchサーバーを起動する\n",
        "\n",
        "※起動の完了には25秒ほどかかる"
      ],
      "metadata": {
        "id": "ViTGdCJbrvG1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7fTG01wCiWW"
      },
      "source": [
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "es_server = Popen([f\"elasticsearch-{ES_VERSION}/bin/elasticsearch\"], \n",
        "                  stdout=PIPE, stderr=STDOUT,\n",
        "                  preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                 )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWK4V22lEiEI"
      },
      "source": [
        "# デバッグ用\n",
        "# while True:\n",
        "#     line = es_server.stdout.readline()\n",
        "#     print(line)\n",
        "#     if not line and es_server.poll() is not None:\n",
        "#         break"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAK-J8wCljc"
      },
      "source": [
        "# サーバー停止\n",
        "# es_server.kill()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# インデックスを作成して検索を試してみる"
      ],
      "metadata": {
        "id": "0EDWp6a8sKGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 起動確認\n",
        "\n",
        "elasticsearchサーバー起動から25秒ほど待ってから実行すること。  \n",
        "起動が完了していないときは次のエラーが発生する。\n",
        "\n",
        "\"curl: (7) Failed to connect to localhost port 9200: Connection refused\""
      ],
      "metadata": {
        "id": "AN3HxgfAt2qx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlzzh6_ECkSG",
        "outputId": "f5ca019c-145e-4d4a-a1dd-7006e6f0f31b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl -X GET \"localhost:9200/\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"2890cd352aee\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"0093OUI9QDa18qYxjo8plw\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.0\",\n",
            "    \"build_flavor\" : \"default\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"a479a2a7fce0389512d6a9361301708b92dff667\",\n",
            "    \"build_date\" : \"2020-08-11T21:36:48.204330Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.0\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## インデックスを作成"
      ],
      "metadata": {
        "id": "URjksj2nt4OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl -H \"Content-Type: application/json\" -XDELETE 'localhost:9200/documents'"
      ],
      "metadata": {
        "id": "c43S7nEs9-ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXbMUxOAFQh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa11777-fd8d-48e5-ca40-2a55054ce0c8"
      },
      "source": [
        "!curl -H \"Content-Type: application/json\" -XPUT 'localhost:9200/documents?pretty' -d '{ \\\n",
        "  \"settings\": { \\\n",
        "    \"index\": { \\\n",
        "      \"number_of_shards\": 1, \\\n",
        "      \"number_of_replicas\": 0 \\\n",
        "    }, \\\n",
        "    \"analysis\": { \\\n",
        "      \"analyzer\": { \\\n",
        "        \"ja\": { \\\n",
        "          \"filter\": [ \\\n",
        "            \"cjk_width\", \\\n",
        "            \"lowercase\" \\\n",
        "          ], \\\n",
        "          \"char_filter\": [ \\\n",
        "            \"html_strip\" \\\n",
        "          ], \\\n",
        "          \"type\": \"custom\", \\\n",
        "          \"tokenizer\": \"ja_tokenizer\" \\\n",
        "        } \\\n",
        "      }, \\\n",
        "      \"tokenizer\": { \\\n",
        "        \"ja_tokenizer\": { \\\n",
        "          \"type\": \"kuromoji_tokenizer\", \\\n",
        "          \"mode\": \"search\" \\\n",
        "        } \\\n",
        "      } \\\n",
        "    } \\\n",
        "  }, \\\n",
        "  \"mappings\": { \\\n",
        "    \"properties\": { \\\n",
        "      \"title\": { \\\n",
        "        \"analyzer\": \"ja\", \\\n",
        "        \"type\": \"text\" \\\n",
        "      }, \\\n",
        "      \"content\": { \\\n",
        "        \"analyzer\": \"ja\", \\\n",
        "        \"type\": \"text\" \\\n",
        "      }, \\\n",
        "      \"genre_id\": { \\\n",
        "        \"type\": \"integer\" \\\n",
        "      }, \\\n",
        "      \"created\": { \\\n",
        "        \"type\": \"date\" \\\n",
        "      } \\\n",
        "    } \\\n",
        "  } \\\n",
        "}'"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"acknowledged\" : true,\n",
            "  \"shards_acknowledged\" : true,\n",
            "  \"index\" : \"documents\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 検索対象ドキュメントの準備\n",
        "\n",
        "livedoorニュースを利用する。"
      ],
      "metadata": {
        "id": "V6RIkIix8i8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O ldcc-20140209.tar.gz https://www.rondhuit.com/download/ldcc-20140209.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5tdvAEA80sC",
        "outputId": "49d10bcc-56e6-4ecf-aacb-1819f596bf3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-11 09:43:29--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  1.62MB/s    in 5.2s    \n",
            "\n",
            "2022-04-11 09:43:35 (1.62 MB/s) - ‘ldcc-20140209.tar.gz’ saved [8855190/8855190]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 正規化処理\n",
        "# https://github.com/neologd/mecab-ipadic-neologd/wiki/Regexp.ja から引用・一部改変\n",
        "from __future__ import unicode_literals\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def unicode_normalize(cls, s):\n",
        "    pt = re.compile('([{}]+)'.format(cls))\n",
        "\n",
        "    def norm(c):\n",
        "        return unicodedata.normalize('NFKC', c) if pt.match(c) else c\n",
        "\n",
        "    s = ''.join(norm(x) for x in re.split(pt, s))\n",
        "    s = re.sub('－', '-', s)\n",
        "    return s\n",
        "\n",
        "def remove_extra_spaces(s):\n",
        "    s = re.sub('[ 　]+', ' ', s)\n",
        "    blocks = ''.join(('\\u4E00-\\u9FFF',  # CJK UNIFIED IDEOGRAPHS\n",
        "                      '\\u3040-\\u309F',  # HIRAGANA\n",
        "                      '\\u30A0-\\u30FF',  # KATAKANA\n",
        "                      '\\u3000-\\u303F',  # CJK SYMBOLS AND PUNCTUATION\n",
        "                      '\\uFF00-\\uFFEF'   # HALFWIDTH AND FULLWIDTH FORMS\n",
        "                      ))\n",
        "    basic_latin = '\\u0000-\\u007F'\n",
        "\n",
        "    def remove_space_between(cls1, cls2, s):\n",
        "        p = re.compile('([{}]) ([{}])'.format(cls1, cls2))\n",
        "        while p.search(s):\n",
        "            s = p.sub(r'\\1\\2', s)\n",
        "        return s\n",
        "\n",
        "    s = remove_space_between(blocks, blocks, s)\n",
        "    s = remove_space_between(blocks, basic_latin, s)\n",
        "    s = remove_space_between(basic_latin, blocks, s)\n",
        "    return s\n",
        "\n",
        "def normalize_neologd(s):\n",
        "    s = s.strip()\n",
        "    s = unicode_normalize('０-９Ａ-Ｚａ-ｚ｡-ﾟ', s)\n",
        "\n",
        "    def maketrans(f, t):\n",
        "        return {ord(x): ord(y) for x, y in zip(f, t)}\n",
        "\n",
        "    s = re.sub('[˗֊‐‑‒–⁃⁻₋−]+', '-', s)  # normalize hyphens\n",
        "    s = re.sub('[﹣－ｰ—―─━ー]+', 'ー', s)  # normalize choonpus\n",
        "    s = re.sub('[~∼∾〜〰～]+', '〜', s)  # normalize tildes (modified by Isao Sonobe)\n",
        "    s = s.translate(\n",
        "        maketrans('!\"#$%&\\'()*+,-./:;<=>?@[¥]^_`{|}~｡､･｢｣',\n",
        "              '！”＃＄％＆’（）＊＋，－．／：；＜＝＞？＠［￥］＾＿｀｛｜｝〜。、・「」'))\n",
        "\n",
        "    s = remove_extra_spaces(s)\n",
        "    s = unicode_normalize('！”＃＄％＆’（）＊＋，－．／：；＜＞？＠［￥］＾＿｀｛｜｝〜', s)  # keep ＝,・,「,」\n",
        "    s = re.sub('[’]', '\\'', s)\n",
        "    s = re.sub('[”]', '\"', s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "jrq-Jvnn9E12"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "target_genres = [\"dokujo-tsushin\",\n",
        "                 \"it-life-hack\",\n",
        "                 \"kaden-channel\",\n",
        "                 \"livedoor-homme\",\n",
        "                 \"movie-enter\",\n",
        "                 \"peachy\",\n",
        "                 \"smax\",\n",
        "                 \"sports-watch\",\n",
        "                 \"topic-news\"]\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = normalize_neologd(text)\n",
        "    return text\n",
        "\n",
        "def read_title_body(file):\n",
        "    next(file)\n",
        "    next(file)\n",
        "    title = next(file).decode(\"utf-8\").strip()\n",
        "    title = normalize_text(title)\n",
        "    body = \"\\n\".join([normalize_text(line.decode(\"utf-8\").strip()) for line in file.readlines()])\n",
        "    return title, body\n",
        "\n",
        "genre_files_list = [[] for genre in target_genres]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "with tarfile.open(\"ldcc-20140209.tar.gz\") as archive_file:\n",
        "    for archive_item in archive_file:\n",
        "        for genre_id, genre in enumerate(target_genres):\n",
        "            if genre in archive_item.name and archive_item.name.endswith(\".txt\"):\n",
        "                genre_files_list[genre_id].append(archive_item.name)\n",
        "\n",
        "    for genre_id, genre_files in enumerate(genre_files_list):\n",
        "        for name in genre_files:\n",
        "            file = archive_file.extractfile(name)\n",
        "            title, body = read_title_body(file)\n",
        "            title = normalize_text(title)\n",
        "            body = normalize_text(body)\n",
        "\n",
        "            if len(title) > 0 and len(body) > 0:\n",
        "                all_data.append({\n",
        "                    \"title\": title,\n",
        "                    \"content\": body,\n",
        "                    \"genre_id\": genre_id,\n",
        "                    \"created\": datetime.now()\n",
        "                    })"
      ],
      "metadata": {
        "id": "jOuEqhGd9M7e"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ドキュメントの登録"
      ],
      "metadata": {
        "id": "SywwmJ3LuC61"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z0bwwwRMOfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b13cc1-81fb-4aa2-d0f3-e3cd31bea964"
      },
      "source": [
        "import gzip, json\n",
        "from elasticsearch import Elasticsearch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "es = Elasticsearch()\n",
        "\n",
        "for id, datum in tqdm(enumerate(all_data), total=len(all_data)):\n",
        "    res = es.index(index=\"documents\", id=id, document=datum)\n",
        "\n",
        "es.indices.refresh(index=\"documents\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7376/7376 [01:35<00:00, 77.48it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_shards': {'failed': 0, 'successful': 1, 'total': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 試しに検索"
      ],
      "metadata": {
        "id": "cdTBpnMABvJ0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVqxIzPaNVyQ",
        "outputId": "61d74df3-bf39-46d6-ce55-30419ed5898b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "es = Elasticsearch()\n",
        "\n",
        "query = {\n",
        "    \"match\": {\n",
        "        \"content\": \"人工知能\"\n",
        "    }\n",
        "}\n",
        "\n",
        "res = es.search(index=\"documents\", query=query, size=10)\n",
        "print(f\"{res['hits']['total']['value']} hits\")\n",
        "for i, hit in enumerate(res['hits']['hits']):\n",
        "    source = hit[\"_source\"]\n",
        "    print(f\"{i+1:2}. ({hit['_score']:0.3f})　{source['title']}\")\n",
        "    # print(f\"{i+1:2}. ({hit['_score']:0.3f})　{source['title']} {source['content']}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41 hits\n",
            " 1. (18.100)　今度はシャープから、人工知能搭載で自ら進んで節電する「プラズマクラスター冷蔵庫」新発売\n",
            " 2. (15.224)　神を自負した男が、無限の野心の果てに追い求めたもの\n",
            " 3. (15.100)　【ニュース】本格運用開始の「グーグル+」、中国では利用不可\n",
            " 4. (15.100)　【話題】押すとしゃべる!テレ東が「ピカチュウリモコン」を7,777名にプレゼント!\n",
            " 5. (14.861)　流行のミラーレスカメラがニコンからもついに!「Nikon 1 J1」「Nikon 1 V1」が発表\n",
            " 6. (14.188)　パナソニックの「旅ナビ」に新モデル登場!「CN-MH01L」はガイドブックデータが充実\n",
            " 7. (13.977)　女性人気の高いミラーレスカメラはオリンパス「PEN E-P3」\n",
            " 8. (13.764)　人工知能からHCIへグーグルの生みの親が語る、コンピューターと人の関係(1)【テレスコープマガジン】\n",
            " 9. (13.193)　シャープ、スマホで部屋の様子を確認できるロボット掃除機「COCOROBO」を発表\n",
            "10. (12.168)　三菱電機から2つのセンサーで自動的に節電可能な頼もしい冷蔵庫「RXシリーズ」が新発売\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGlONFSuqTzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}